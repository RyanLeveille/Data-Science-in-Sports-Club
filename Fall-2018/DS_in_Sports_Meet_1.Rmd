---
title: "DS in Sports, Meeting 1."
author: "Yo"
date: "September 6, 2018"
output:
  html_document: default
  pdf_document: default
---

First, we install some $R$ libraries: 

- $rvest$ is needed for scraping (should be installed along with $xml2$)

- $plotrix$ is needed for nice 2D map plots.

```{r, include = F}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, error=T)
```

```{r}
library(rvest)  # Should be installed along with 'xml2'
library(plotrix) # Also install it please.
```

Below, we supply a url address with data of interest and read it via $read\_html()$ function.
```{r}
url_link <- 'https://www.sports-reference.com/cfb/schools/houston/2017/gamelog/'

# Read the HTML webpage for that link into an R object
url <- read_html(url_link) 
```

If we look at the actual webpage corresponding to this url address, we see there's two clear-cut data tables. The first table could be extracted from the page via the following code:
```{r, message=F, warning=F}
# Find a 'table' on that HTML page
table_one <- xml_find_all(url, "//table") 
class(table_one)

# Obtain the actual contents of the table, wrapped into a data frame
table_one <- html_table(table_one)
class(table_one)

table_one
length(table_one)

table_one[[1]]
class(table_one[[1]])
```

```{r}
head(table_one[[1]])
```

Looks promising, but there's one big issue - there were two header rows in the table, and only the first one got accounted for. Hence the second header row ('Rk', 'Date', 'Opponent' etc) is considered as the first *observation* rather than *column names*. 

That can be fixed via hard-coding (reassigning a data frame with the first header row completely removed):
```{r}
tab.col.names <- table_one[[1]][1,]
table_one[[1]] <- table_one[[1]][-1,]
colnames(table_one[[1]]) <- tab.col.names
head(table_one[[1]])
```

Also, we don't quite need the LAST ROW, which is just totals for the year: we can always calculate those on our own.
```{r}
table_one[[1]] <- table_one[[1]][-nrow(table_one[[1]]),]
```

Let's now take some variable summaries, e.g. average no. of completions:
```{r}
mean(table_one[[1]]$Cmp)
```

What's wrong? Use $summary()$ to check the types of variables in data frame resulting from $read\_html()$ operation.
```{r}
summary(table_one[[1]])
```
or another way is via function $str()$
```{r}
str(table_one[[1]])
```


All are automatically treated as characters. We'd like to convert most of those (but NOT ALL) to numeric. In particular, everything except Date, Home/Away marker, Opponent and Result. Function $as.numeric()$ comes to rescue.
```{r}
head(table_one[[1]])
table_one[[1]][,-c(2:5)] <- lapply(table_one[[1]][,-c(2:5)],as.numeric)

# Now verify that everything is in order:
summary(table_one[[1]])
str(table_one[[1]])
```


Next, we could play around with pairwise scatterplots for variables in the data set. Make sure to only consider *numerical* variables (no factors or characters). 
```{r}
#pairs(table_one[[1]]) # Error - get rid of non-numerical stuff

pairs(table_one[[1]][,-c(1:5)])  # A bit problematic to read, isn't it?
```

A bit problematic to read, isn't it? Let's scale down and just look at **subsets of variables**:

```{r}
# Let's just look at subsets of variables
pairs(table_one[[1]][,c(6:10)])
pairs(table_one[[1]][,c(11:19)])
```

In all honesty, there's not too much you can ever see from 12 data points. Hence we proceed to obtaining data on more college football teams.

## Getting data on more teams.

Let's get tables on several teams, to obtain a larger sample of games. For that, first we need to specify the url-versions of team names we're interested in. For the time being, let's just limit ourselves to UH, Rice, Texas Tech, Temple \& Tulsa.
```{r}
team_names <- c('houston', 'rice', 'texas-tech','temple','tulsa')
```

Next, we need to code up a method to automatically create a full URL for each team name. It is done via $paste()$ function. E.g., how can we get the name

"https://www.sports-reference.com/cfb/schools/houston/2017/gamelog/"


 via $paste()$ function and the team name *'houston'*?

```{r}
url_link <- paste('https://www.sports-reference.com/cfb/schools/',team_names[1],'/2017/gamelog/')
url_link
```

Issue here? There are white spaces at string connection points. Use **'sep=' option** to get rid of those.

```{r}
url_link <- paste('https://www.sports-reference.com/cfb/schools/',team_names[1],'/2017/gamelog/',
                  sep="")
url_link
```

From now on, in order to obtain data on UH, we could simply apply all of the aforementioned code to this calculated url.

Now, how do we automatically loop through all the team names? Easy:
 
 Loop through indices (i=1,...,5), where for each i we:
 
 1. Calculate the url for $team\_names[i]$.
 
 2. Extract the table.

We'll keep all the tables in one big data frame object $offense\_data$, and also replace the useless first column ('Rk') with a team name column: 

```{r}
offense_data <- NULL
team_names <- c('houston', 'rice', 'texas-tech','temple','tulsa')

for (i in 1:length(team_names)){
  url_link <- paste('https://www.sports-reference.com/cfb/schools/',team_names[i],'/2017/gamelog/',
                    sep="") 
  url <- read_html(url_link) 
  table_one <- xml_find_all(url, "//table")
  table_one <- html_table(table_one)[[1]]
  
  tab.col.names <- table_one[1,]
  table_one <- table_one[-1,]
  colnames(table_one) <- tab.col.names
  
  table_one <- table_one[-nrow(table_one),]
  table_one[,-c(2:5)] <- lapply(table_one[,-c(2:5)],as.numeric)
  table_one[,1] <- team_names[i]
  colnames(table_one)[1] <- "Team"
  
  print(head(table_one,2)) # Print out the header from extracted table for the team.
  cat("\n")
  offense_data <- rbind(offense_data, table_one)
}


dim(offense_data)
head(offense_data)
```

Before proceeding, let's save our scraped offensive logs into a file $Scraped\_Offense.txt$.

```{r}
write.table(offense_data,"Scraped_Offense.txt")
```


Now that we have combined data for five teams, resulting into a total of roughly 60 observations, let's get pairwise scatterplots for different variables
```{r}
pairs(offense_data[,c(6:10)])
pairs(offense_data[,c(11:19)])
```

Pretty clogged up and tough to interpret. To substitute these messy plots for a nice numerical summary, let's calculate all pairwise *correlations* via $cor()$ function applied to all numeric variables.
```{r}
## Get correlation matrix.
offense_data_num <- offense_data[,-c(1:5)]
cor(offense_data_num)  # Tough to read.
```
The matrix in itself is pretty bulky, but we could *plot* it with the help of *$plotrix$ package* and its function $color2D.matplot()$. Don't get too preoccupied with the $cs1-cs3$ arguments - they control the color scheme of the plot, and I've simply set them to take on darker color for larger correlation values.

```{r}
library(plotrix)
color2D.matplot(cor(offense_data_num),
                cs1=c(1,0),cs2=c(1,0),cs3=c(1,0),
                show.legend=T)
```

Issue with this plot is that we are not really interested in sign of correlation (whether it's positive or negative). Knowing the strength of correlation would do it for us. Apply $abs()$ function.

```{r}
color2D.matplot(abs(cor(offense_data_num)),
                cs1=c(1,0),cs2=c(1,0),cs3=c(1,0),
                show.legend=T)
```


Cleaner, but still a bit dirty. We could *threshold* values, so that all correlations less than the thresholds are SET TO 0. This may be done via $ifelse()$. Below I set to zero all the correlations that are below 0.8 in absolute value.
```{r}
abs.cor.mat <- abs(cor(offense_data_num))
color2D.matplot(ifelse(abs.cor.mat>=0.8, abs.cor.mat,0),
                cs1=c(1,0),cs2=c(1,0),cs3=c(1,0),
                show.legend=T)
colnames(abs.cor.mat)  # To know which row/column corresponds to which variable.
```


To pretty up the plot and make it much more informative, we could take numerous steps. One of them - making the variable names show up along rows and columns. Functions $axis()$ and $par()$ (with its $las$ option that dictates whether text is printed vertically or horizontally) help us with that.
```{r}
color2D.matplot(ifelse(abs.cor.mat>=0.8, abs.cor.mat,0),
                cs1=c(1,0),cs2=c(1,0),cs3=c(1,0),
                show.legend = T,
                xlab='',
                ylab='',
                axes=F)
par(las=2)
axis(1,at=c(1:ncol(abs.cor.mat))-0.5,labels=colnames(abs.cor.mat))
par(las=1)
axis(2,at=c(ncol(abs.cor.mat):1)-0.5,labels=colnames(abs.cor.mat))
```